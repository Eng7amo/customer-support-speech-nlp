{"cells":[{"source":"<p align=\"center\" width=\"100%\">\n    <img width=\"40%\" src=\"customer_support_icon.JPG\"> \n</p>\n\nA retail company is on a transformative journey, aiming to elevate their customer services through cutting-edge advancements in Speech Recognition and Natural Language Processing (NLP). As the machine learning engineer for this initiative, you are tasked with developing functionalities that not only convert customer support audio calls into text but also explore methodologies to extract insights from transcribed texts.\n\nIn this dynamic project, we leverage the power of `SpeechRecognition`, `Pydub`, and `spaCy` – three open-source packages that form the backbone of your solution. Your objectives are:\n  - Transcribe a sample customer audio call, stored at `sample_customer_call.wav`, to showcase the power of open-source speech recognition technology.\n  - Analyze sentiment, identify common named entities, and enhance user experience by searching for the most similar customer calls based on a given query from a subset of their pre-transcribed call data, stored at `customer_call_transcriptions.csv`.\n\nThis project is an opportunity to unlock the potential of machine learning to revolutionize customer support. Let's delve into the interplay between technology and service excellence.","metadata":{},"id":"d5e81b43-ccfd-4fc6-902c-59cd49aa9913","cell_type":"markdown"},{"source":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","metadata":{"executionCancelledAt":null,"executionTime":19373,"lastExecutedAt":1763876501369,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","outputsMetadata":{"0":{"height":613,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"b590abed-53c7-477d-98fc-1723369e8a9a"},"id":"d0f1598e-18a8-45d5-8387-bf2f5ce4ffd6","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: SpeechRecognition in /home/repl/.local/lib/python3.8/site-packages (3.10.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.31.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2019.11.28)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pydub in /home/repl/.local/lib/python3.8/site-packages (0.25.1)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.1.1)\nDefaulting to user installation because normal site-packages is not writeable\nCollecting en-core-web-sm==3.6.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n"}]},{"source":"# Import required libraries\nimport pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1763876501427,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","outputsMetadata":{"0":{"height":77,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"b590abed-53c7-477d-98fc-1723369e8a9a"},"id":"d6f3dd61-8c75-48d4-b2a5-79cd0b444ddb","cell_type":"code","execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/repl/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"}]},{"source":"# -----------------------------\n# 1. IMPORT LIBRARIES\n# -----------------------------\nimport pandas as pd\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport nltk\nnltk.download(\"vader_lexicon\")\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# -----------------------------\n# 2. SPEECH RECOGNITION\n# -----------------------------\nrecognizer = sr.Recognizer()\n\nwith sr.AudioFile(\"sample_customer_call.wav\") as source:\n    audio_data = recognizer.record(source)\n\n# Transcribe audio\ntranscribed_text = recognizer.recognize_google(audio_data)\n\n# Extract audio stats\naudio_seg = AudioSegment.from_file(\"sample_customer_call.wav\")\nframe_rate = audio_seg.frame_rate\nnumber_channels = audio_seg.channels\n\n# -----------------------------\n# 3. SENTIMENT ANALYSIS\n# -----------------------------\n# Load your dataset (your file uses column: text)\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsia = SentimentIntensityAnalyzer()\n\n# Sentiment classifier\ndef classify_sentiment(text):\n    scores = sia.polarity_scores(str(text))\n    comp = scores[\"compound\"]\n    if comp >= 0.05:\n        return \"positive\"\n    elif comp <= -0.05:\n        return \"negative\"\n    else:\n        return \"neutral\"\n\n# Apply classifier to correct column name → \"text\"\ndf[\"sentiment_predicted\"] = df[\"text\"].apply(classify_sentiment)\n\n# REQUIRED: submission variable\npredicted = df[\"sentiment_predicted\"]\n\n# Count true positives\ntrue_positive = df.loc[\n    (df[\"sentiment_label\"] == \"positive\") &\n    (df[\"sentiment_predicted\"] == \"positive\")\n].shape[0]\n\n# -----------------------------\n# 4. NAMED ENTITY RECOGNITION\n# -----------------------------\nall_entities = []\n\nfor text in df[\"text\"]:\n    doc = nlp(str(text))\n    for ent in doc.ents:\n        all_entities.append(ent.text)\n\nmost_freq_ent = (\n    pd.Series(all_entities).value_counts().idxmax()\n    if all_entities else \"\"\n)\n\n# -----------------------------\n# 5. MOST SIMILAR TEXT SEARCH\n# -----------------------------\nquery = \"wrong package delivery\"\nquery_doc = nlp(query)\n\nbest_score = -1\nmost_similar_text = \"\"\n\nfor text in df[\"text\"]:\n    doc = nlp(str(text))\n    score = query_doc.similarity(doc)\n    if score > best_score:\n        best_score = score\n        most_similar_text = text\n\n# -----------------------------\n# PRINT RESULTS\n# -----------------------------\nprint(\"Transcribed Text:\", transcribed_text)\nprint(\"Frame Rate:\", frame_rate)\nprint(\"Channels:\", number_channels)\n\nprint(\"\\nTrue Positive:\", true_positive)\nprint(\"Most Frequent Entity:\", most_freq_ent)\nprint(\"Most Similar Text:\", most_similar_text)\n\nprint(\"\\nPredicted column preview:\")\nprint(predicted.head())\n","metadata":{"executionCancelledAt":null,"executionTime":2824,"lastExecutedAt":1763876504251,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# -----------------------------\n# 1. IMPORT LIBRARIES\n# -----------------------------\nimport pandas as pd\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport nltk\nnltk.download(\"vader_lexicon\")\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# -----------------------------\n# 2. SPEECH RECOGNITION\n# -----------------------------\nrecognizer = sr.Recognizer()\n\nwith sr.AudioFile(\"sample_customer_call.wav\") as source:\n    audio_data = recognizer.record(source)\n\n# Transcribe audio\ntranscribed_text = recognizer.recognize_google(audio_data)\n\n# Extract audio stats\naudio_seg = AudioSegment.from_file(\"sample_customer_call.wav\")\nframe_rate = audio_seg.frame_rate\nnumber_channels = audio_seg.channels\n\n# -----------------------------\n# 3. SENTIMENT ANALYSIS\n# -----------------------------\n# Load your dataset (your file uses column: text)\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsia = SentimentIntensityAnalyzer()\n\n# Sentiment classifier\ndef classify_sentiment(text):\n    scores = sia.polarity_scores(str(text))\n    comp = scores[\"compound\"]\n    if comp >= 0.05:\n        return \"positive\"\n    elif comp <= -0.05:\n        return \"negative\"\n    else:\n        return \"neutral\"\n\n# Apply classifier to correct column name → \"text\"\ndf[\"sentiment_predicted\"] = df[\"text\"].apply(classify_sentiment)\n\n# REQUIRED: submission variable\npredicted = df[\"sentiment_predicted\"]\n\n# Count true positives\ntrue_positive = df.loc[\n    (df[\"sentiment_label\"] == \"positive\") &\n    (df[\"sentiment_predicted\"] == \"positive\")\n].shape[0]\n\n# -----------------------------\n# 4. NAMED ENTITY RECOGNITION\n# -----------------------------\nall_entities = []\n\nfor text in df[\"text\"]:\n    doc = nlp(str(text))\n    for ent in doc.ents:\n        all_entities.append(ent.text)\n\nmost_freq_ent = (\n    pd.Series(all_entities).value_counts().idxmax()\n    if all_entities else \"\"\n)\n\n# -----------------------------\n# 5. MOST SIMILAR TEXT SEARCH\n# -----------------------------\nquery = \"wrong package delivery\"\nquery_doc = nlp(query)\n\nbest_score = -1\nmost_similar_text = \"\"\n\nfor text in df[\"text\"]:\n    doc = nlp(str(text))\n    score = query_doc.similarity(doc)\n    if score > best_score:\n        best_score = score\n        most_similar_text = text\n\n# -----------------------------\n# PRINT RESULTS\n# -----------------------------\nprint(\"Transcribed Text:\", transcribed_text)\nprint(\"Frame Rate:\", frame_rate)\nprint(\"Channels:\", number_channels)\n\nprint(\"\\nTrue Positive:\", true_positive)\nprint(\"Most Frequent Entity:\", most_freq_ent)\nprint(\"Most Similar Text:\", most_similar_text)\n\nprint(\"\\nPredicted column preview:\")\nprint(predicted.head())\n","outputsMetadata":{"0":{"height":80,"type":"stream"},"1":{"height":332,"type":"stream"}},"lastExecutedByKernel":"b590abed-53c7-477d-98fc-1723369e8a9a"},"id":"250524c2-1bd3-4ff8-a224-8fa007566c1b","cell_type":"code","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/repl/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"},{"output_type":"stream","name":"stdout","text":"Transcribed Text: hello I'm experiencing an issue with your product I'd like to speak to someone about a replacement\nFrame Rate: 44100\nChannels: 1\n\nTrue Positive: 2\nMost Frequent Entity: yesterday\nMost Similar Text: wrong package delivered\n\nPredicted column preview:\n0    negative\n1    positive\n2    negative\n3     neutral\n4     neutral\nName: sentiment_predicted, dtype: object\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}